{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Google_Search.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install azure-storage-blob\n",
        "#!python -m nltk.downloader stopwords\n",
        "#!python -m nltk.downloader punkt\n",
        "#!pip install fake_useragent\n",
        "#!pip install selenium\n",
        "#!pip install webdriver_manager\n",
        "#!apt install chromium-chromedriver\n",
        "#!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "metadata": {
        "id": "G-50XbcbqDcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:#FF00FF\">Import libraries</span>"
      ],
      "metadata": {
        "id": "Vn396ghwvDtc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQ-6w1whjhR9"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "\n",
        "import string\n",
        "import unicodedata\n",
        "import html\n",
        "import time\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from fake_useragent import UserAgent\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "from bs4.element import Comment\n",
        "\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, __version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def configure_driver():\n",
        "    ua = UserAgent()\n",
        "    user_agent = ua.random\n",
        "    print(user_agent)\n",
        "    options = Options()\n",
        "    options.add_argument(f'user-agent = {user_agent}')\n",
        "    options.add_argument('--headless')\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome('chromedriver', options = options)\n",
        "    return driver"
      ],
      "metadata": {
        "id": "AQr4YQWVIhsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:#FF00FF\">Define Parameters</span>"
      ],
      "metadata": {
        "id": "YZD6xc3ax4BC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {\n",
        "    'app_client': 'consumer_web',\n",
        "    'content-type': 'application/json',\n",
        "    'user-agent': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.61 Safari/537.36',\n",
        "    'accept': '*/*',\n",
        "}\n",
        "\n",
        "url = 'https://www.google.com/search?q=$'\n",
        "\n",
        "params = {\n",
        "      \"q\": \"\",\n",
        "      \"hl\": \"en\",\n",
        "      \"gl\": \"us\"\n",
        "    }\n",
        "\n",
        "\n",
        "sub_search = ['about us',\n",
        "              'company profile',\n",
        "              'leadership team',\n",
        "              'holding patterns',\n",
        "              'diverse certificate', \n",
        "              'public company']\n",
        "\n",
        "\n",
        "#Blob Storage Connection\n",
        "çompany_list = \"dnbcompanieslist.csv\"\n",
        "connect_str=\"DefaultEndpointsProtocol=https;AccountName=seagullsstorage;AccountKey=1W2VlvlzxmzzQcRUULCSjFuhhTpGluxPBymj2Et4SCfTOpwPLZqquLW3qKl46+sMohn+SdvQkKsI+AStmcLbHQ==;EndpointSuffix=core.windows.net\"\n",
        "blob_service_client = BlobServiceClient.from_connection_string(connect_str)\n",
        "container_client = blob_service_client.get_container_client(\"googlesearch\")"
      ],
      "metadata": {
        "id": "guJHkRGYj0nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:#FF00FF\">Custom Google Search</span>"
      ],
      "metadata": {
        "id": "yQXnknWgyLq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a class to do googlesearch. \n",
        "class googlesearch:\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def google_search(self,query):\n",
        "      \n",
        "      cleanString = re.sub('\\W+',' ', query ).strip()\n",
        "\n",
        "      qurl = url.replace('$',cleanString)\n",
        "      \n",
        "      details_driver.get(qurl)\n",
        "      soup = BeautifulSoup(details_driver.page_source)\n",
        "      \n",
        "      #links = soup.findAll(\"a\")\n",
        "      links = []\n",
        "      for link in  soup.find_all(\"a\",href=re.compile(\"(htt.*://.*)\")):\n",
        "          l = re.split(\":(?=http)\",link[\"href\"])[0]\n",
        "          if 'google' not in l and not l.endswith('pdf'):\n",
        "              links.append(l) \n",
        "      return links\n",
        "      \n",
        "\n",
        "    def get_links(self,query):\n",
        "      query_list = [query]\n",
        "      add_list  = list(map(lambda x: query +\" \"+ x, sub_search))\n",
        "      query_list.extend(add_list)\n",
        "      links = []\n",
        "      for query in query_list:\n",
        "        try:\n",
        "          tmp_link = self.google_search(query)\n",
        "          links.extend(tmp_link)\n",
        "        except:\n",
        "          pass\n",
        "      return list(set(links))\n",
        "\n",
        "\n",
        "    def tag_visible(self,element):\n",
        "        if element.parent.name in ['style', 'script', 'head', 'title', 'meta', '[document]']:\n",
        "            return False\n",
        "        if isinstance(element, Comment):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "\n",
        "    def text_from_html(self,body):\n",
        "        texts = body.findAll(text=True)\n",
        "        visible_texts = filter(self.tag_visible, texts)  \n",
        "        return u\" \".join(t.strip() for t in visible_texts)\n",
        "\n",
        "    def get_pagecontent(self,query):\n",
        "      context = []\n",
        "      time.sleep(2)\n",
        "      links = self.get_links(query)\n",
        "      source = 'google'\n",
        "      for link in tqdm(links):\n",
        "        #print(link)\n",
        "        try:\n",
        "          details_driver.get(link)\n",
        "          print(link)\n",
        "          soup = BeautifulSoup(details_driver.page_source, 'html.parser')\n",
        "          text = self.text_from_html(soup)\n",
        "          context.append([source,query,link,text])\n",
        "        except Exception as e:\n",
        "          print('Exception raised',e)\n",
        "          pass\n",
        "      return context"
      ],
      "metadata": {
        "id": "2Nf8I-9qkDWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:#FF00FF\">Get Company List</span>"
      ],
      "metadata": {
        "id": "PyTuuyISyumy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bc = container_client.get_blob_client(blob=çompany_list)\n",
        "\n",
        "data = bc.download_blob()\n",
        "with open(çompany_list, \"wb\") as f:\n",
        "   data.readinto(f)\n",
        "companies = pd.read_csv(çompany_list,sep=\",\", encoding='cp1252')\n",
        "\n",
        "#First 10 company Names\n",
        "company_names = companies.dunsName[0:10]\n"
      ],
      "metadata": {
        "id": "ciLm8B8fo135"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:#FF00FF\">Web Scrapping</span>"
      ],
      "metadata": {
        "id": "x2tFmCR7y6_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "details_driver = configure_driver()\n",
        "#adding a time limit of 20 seconds to load the page\n",
        "details_driver.set_page_load_timeout(20)\n",
        "\n",
        "columns = ['source','search','link','content']\n",
        "df = pd.DataFrame(columns = columns)\n",
        "\n",
        "search = googlesearch()\n",
        "\n",
        "company_names = ['Wong Potatoes, Inc']\n",
        "for company in tqdm(company_names):\n",
        "  content = search.get_pagecontent(company)\n",
        "  tmp = pd.DataFrame(content,columns = columns)\n",
        "  df = df.append(tmp, ignore_index = True)"
      ],
      "metadata": {
        "id": "JOFEIEVSkG3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_bak = df.copy()"
      ],
      "metadata": {
        "id": "BcRXQ-ot0ucI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:#800000\">Data Cleaning</span>"
      ],
      "metadata": {
        "id": "Z9hcGONtDGOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a class to get clean text. \n",
        "class preprocessing:\n",
        "    \n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    #Cleaning and stripping HTML\n",
        "    def remove_html_tags(self,text):\n",
        "        clean = re.compile('<.*?>')\n",
        "        cleantext = re.sub(clean, '', text)\n",
        "        return cleantext\n",
        "\n",
        "    #Removing Escaping characters &lt\n",
        "    def escaping_html_char(self,doc):\n",
        "        cleandoc = html.unescape(doc)\n",
        "        return cleandoc\n",
        "    \n",
        "    #Removing newline & extra spaces\n",
        "    def textcleaning(self,doc):\n",
        "        # remove extra newlines\n",
        "        a = doc.replace(\"\\\\n\",\".\").strip()\n",
        "        a = a.replace(\"\\\\r\",\".\").strip()\n",
        "        #a = re.sub(r'\\d+','',a)# remove numbers\n",
        "        cleandoc = re.sub(\"\\s+\",\" \", a)\n",
        "        return cleandoc\n",
        "    \n",
        "    def text_norm(self,doc):\n",
        "        cleandoc = doc.lower()\n",
        "        return cleandoc\n",
        "    \n",
        "\n",
        "    # Removing accented characters\n",
        "    # A simple example — converting é to e.\n",
        "    def decode_text(self,doc):\n",
        "        cleandoc = unicodedata.normalize('NFKD', doc).encode('ascii','ignore').decode(\"utf8\")\n",
        "        return cleandoc\n",
        "    \n",
        "    def text_tokenize(self,doc):\n",
        "        return word_tokenize(doc)\n",
        "    \n",
        "    def remove_stopwords(self,words):\n",
        "        # set of stop words\n",
        "        stop_words = set(stopwords.words('english')) \n",
        "        stext = [] \n",
        "        for w in words:\n",
        "            if w not in stop_words:\n",
        "                stext.append(w)\n",
        "        return stext\n",
        "    \n",
        "    def remove_punctuation(self,doc):\n",
        "        #chars = '!\"#$%&\\'()*+,-/:;<=>?@[\\\\]^_`{|}~'\n",
        "        #table = str.maketrans(chars, ' '*len(chars))\n",
        "        table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "        ##str.maketrans('', '', string.punctuation)\n",
        "        cleandoc = doc.translate(table)\n",
        "        cleandoc=re.sub(r'[\\W_]+', ' ', cleandoc)\n",
        "        return cleandoc\n",
        "    \n",
        "    \n",
        "    def questions_clean(self,text):\n",
        "        text = re.sub(r'\\n+', '\\n', text).strip()\n",
        "        return text\n",
        "    \n",
        "    \n",
        "    def data_preprocessing(self,doc):\n",
        "        doc = str(doc)\n",
        "\n",
        "        step1 = self.remove_html_tags(doc)            # Cleaning and stripping HTML\n",
        "        step2 = self.escaping_html_char(step1)        # Removing Escaping characters &lt\n",
        "        step3 = self.textcleaning(step2)              # Removing newline & extra spaces\n",
        "        step4 = self.text_norm(step3)                 # Case Normalization\n",
        "        step5 = self.remove_punctuation(step4)        # Remove punctuation\n",
        "        step6 = self.decode_text(step5)               # Text encoding - Removing accented characters\n",
        "        step7 = self.text_tokenize(step6)             # Tokenization\n",
        "        step8 = self.remove_stopwords(step7)          # Stop Words\n",
        "        \n",
        "        return \" \".join(step8)"
      ],
      "metadata": {
        "id": "8JDJi3ekxlRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:#800000\">Pre Processing</span>"
      ],
      "metadata": {
        "id": "7J3MhxsMDLyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre = preprocessing()\n",
        "df['content_clean'] = df['content'].apply(pre.data_preprocessing)"
      ],
      "metadata": {
        "id": "wjyv0i-OBfg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:#800000\">Azure Blob - Upload Files</span>"
      ],
      "metadata": {
        "id": "EljHHAkrXuwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "comp_lst = df.search.unique()\n",
        "\n",
        "for comp in comp_lst:\n",
        "  tmp_df = df[df.search==comp]\n",
        "  comp = pre.data_preprocessing(comp)\n",
        "  for i,(index, row) in enumerate(tmp_df.iterrows()):\n",
        "    rj = row.to_json()\n",
        "    parsed = json.loads(rj)\n",
        "    data = json.dumps(parsed,indent=4)\n",
        "    \n",
        "    blobname = '{0}/content_{1}.json'.format(comp, i)\n",
        "    #print(blobname)\n",
        "    container_client.upload_blob(name=blobname, data=data,overwrite = True)"
      ],
      "metadata": {
        "id": "sqz18vhjHbE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <span style=\"color:#800000\">Azure Blob - Delete Files</span>"
      ],
      "metadata": {
        "id": "ju2FF6L1X1HO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete\n",
        "blob_list = container_client.list_blobs()\n",
        "\n",
        "for blob in blob_list:\n",
        "  #print(blob.name)\n",
        "  if not('dnb' in blob.name):\n",
        "    container_client.delete_blob(blob.name)\n",
        "  else:\n",
        "    print(blob.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd_FmwU9V4q5",
        "outputId": "cba2d6c1-acc9-42b1-f284-d66fc2773ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dnbcompanieslist.csv\n"
          ]
        }
      ]
    }
  ]
}